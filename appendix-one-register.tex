\section{Well-typedeness and normalisation of $\lambda$-terms in first-order logic}
\label{sec:eval}


\newcommand{\NonLinTerms}[2]{\Lambda_{#1} #2}
 \newcommand{\rlambda}{\ranked{\Lambda}}
 \newcommand{\rlambdalin}{\ranked{\Lambda^{\sf{lin}}}}
 \newcommand{\rlambdathin}{\ranked{\Lambda^{\sf{thin}}}}
\newcommand{\pictureline}[2]{\\   \begin{minipage}{0,6\textwidth}
    #1 
\end{minipage} & \begin{minipage}{0,4\textwidth}#2\end{minipage} \\}

\newcommand{\thinterm}[1]{\ranked{\mathsf{Thin}_{#1}}}

\subsection{Well-typedeness}
A natural question to ask about $\lambda$-terms in our framework is whether their well-typedeness is a first-order property. Without restriction on the terms, the answer is negative as shown by the following example.

\begin{example}
Consider the set of typed variables $X=\{x:o, y:o\rightarrow o, z:o\rightarrow(o\rightarrow o), t:o, u:o\rightarrow o\}$ and the set of $\lambda$-terms $(M_n)_{n\in \mathbb{N}}$ defined by induction as follows: 
\begin{align*}
M_0 &= u(yx)\\
M_{n+1}&= (\lambda y.\lambda x. M_n)(z(yx))
\end{align*}
The type of $M_n$ is $o^n\rightarrow o$ where $o^n\rightarrow o$ stands for $\underbrace{o\rightarrow\dots\rightarrow o}_{n \text{ times}}\rightarrow o$ when $n>0$ and for $o$ otherwise. 

Consider now the set of $\lambda$-terms $(L_{m,n})_{m,n\in \mathbb{N}}$ defined by induction on $m$ as follows:
\begin{align*}
L_{0,n}&= M_n \\
L_{m+1, n}&=L_{m,n}t
\end{align*}
When $m\leq n$, the $\lambda$-term $L_{m,n}$ is well-typed and its type is $o^{m-n}\rightarrow o$, otherwise it is not well-typed. If well-typedeness was an fo property, we would be able to make such tests on natural numbers which is clearely not the case. 
\end{example}

When we restrict our attention to those $\lambda$-terms whose subterms have types in a fixed finite set of types $S$, well-typedeness becomes a first-order property. Note that contrarily to $\beta$-reduction, well-typedeness does not require linearity to be in fo.

\begin{proposition}\label{prop:WellTypedFo}
    For every typed set $X$ and every finite set $S$ of simple types, the tree language 
    \begin{align*}
    \NonLinTerms S X  := \set{ M \in \trees \lamrank X : \text{$M$ is well-typed and all subterms have type in $S$}}
    \end{align*}
    is first-order definable 
\end{proposition}

To prove this property, we will start by showing that for $\NonLinTerms S X$ terms (that is if we already know that a term is well-typed and that all its sub-terms have types in $S$) checking if their type is $\tau$, where $\tau$ is a type in $S$, is a first order property:
\begin{lemma}\label{lem:IsTypeTauFo}
For every simple type $\tau$ in $S$, there is a first-order query $\varphi_\tau$ such that:
$$ \forall M\in \NonLinTerms S X \qquad M,u \models \varphi_\tau \Longleftrightarrow M|_u:\tau$$
where $M|_u$ is the subterm of $M$ rooted in $u$. 
\end{lemma}
Before establishing this lemma, let us see how property~\ref{prop:WellTypedFo} can be derived from it. Suppose for convenience that the types of the variables of $X$  are in $S$, and that $S$ is downward closed. Let $\varphi$ be the following first-order formula:
\begin{align*}
\forall u. \bigvee_{\sigma\rightarrow\tau\in S} \left(\bigvee_{x:\sigma}\lambda x(u) \Rightarrow
 \varphi_{\sigma\rightarrow\tau}(u)\wedge\varphi_\tau(\mathrm{child}_1(u))\right) \wedge 
\left(\text{@}(u) \Rightarrow \varphi_{\sigma\rightarrow\tau}(\mathrm{child}_1(u))\wedge\varphi_\sigma(\mathrm{child}_2(u))\right)
\end{align*}
If a $\lambda$-term is in $\NonLinTerms S X$, then it clearly satisfies $\varphi$. Suppose by contradiction that there is a $\lambda$-term $M$ which is not in $\NonLinTerms S X$ and yet satisfies $\varphi$. let $u$  be the deapest node of $M$ which is not in $\NonLinTerms S X$ (we identify in this proof a node $u$ and the subterm $M|_u$). In particular, the descendents of $u$ are all in $\NonLinTerms S X$. The node $u$ cannot be a variable, since we supposed that the types of the variables $X$ are in $S$. If $u$ was labeled by $\lambda x$, where $x$ is of type $\sigma$, then by the first conjunct of $\varphi$ there is a type $\tau$ such that $\sigma\rightarrow\tau\in S$ and the child $v$ of $u$  satisfies $\varphi_\tau$. Since $v$ is in $\NonLinTerms S X$, its type is $\tau$ by Lemma~\ref{lem:IsTypeTauFo}. Hence $u$ is well-typed and its type is $\sigma\rightarrow\tau\in S$. As a consequence $u$ is in $\NonLinTerms S X$ which is a contradiction.  Finally, if $u$ was labeled by @, then by the second conjunct of $\varphi$, its two children $u_1$ and $u_2$
would satisfy respectively $\varphi_{\sigma\rightarrow\tau}$ and  $\varphi_{\sigma}$ and by Lemma~\ref{lem:IsTypeTauFo} they are of type $\sigma\rightarrow\tau$ and $\sigma$ respectively. The node $u$ is then well-typed and its type is $\tau$ (which is a type of $S$ thanks to downward closeness). As a consequence, $u$ is in $\NonLinTerms S X$, wich gives a contradiction and concludes the proof.
 
We can go back now to the proof of Lemma~\ref{lem:IsTypeTauFo}.
\begin{proof}[Proof of Lemma~\ref{lem:IsTypeTauFo}]
Let us show that checking whether the type of a $\NonLinTerms S X$ term is $\tau$ is a first-order query. For that, notice that the type of a well-typed term depends only on its left-most branch. In fact, the type of a term is exactly the type of its left-most branch in the following sens.

Consider the (unranked) alphabet $ X_\lambda:= X\cup \{\text{@}, \lambda x | x\in X\}$. We can equip the words over $X_\lambda$ with the following typing rules:
$$\frac{}{x: \sigma} \qquad \frac{u:\tau}{u\lambda x: \sigma\rightarrow \tau} \qquad \frac{u:\sigma\rightarrow\tau}{u\text{@}:\tau}\qquad\text{(where $x$ is of type $\sigma$ and $\sigma,\tau \in S$)}$$
We say that $w$ is of type $\tau$ and write $w:\tau$ if there is a typing derivation for $w:\tau$.

We can associate to every branch of a $\lambda$-term a word over $X_\lambda$ corresponding to the sequence of its labels read bottom-up. By induction on $\lambda$-terms, we can easily show that the type of a $\lambda$-term is the type of the word corresponding to its leftmost branch. 

By this last observation, we can reduce the query asking if the type of a term is $\tau$, to the same query but on $X_\lambda$ words. To show that the former is a first-order query, it is then sufficient to show that the following word language 
\begin{align*}
W_\tau = \{w\in X.\{\text{@}, \lambda x | x\in X\}^*\ |\ w:\tau \} 
\end{align*}
is first-order definable, or equivalently that  $W_\tau$ is recognized by a counter-free non-deterministic finite automaton. For that we proceed as follows: first, we show that $W_\tau$ is recognized by a pushdown automaton $A_\tau$. Then we will show that the stack height of $A_\tau$ is bounded, thus it can be turned into a non-deterministic finite automaton $N_\tau$. Finally, we show that the obtained automaton $N_\tau$ is actually counter-free.  

For a formal definition of pushdown automata (PDA) and (counter-free) non-deterministic finite automata (NFA) see~\ref{}.

Consider the following PDA $A_\tau$ whose
\begin{itemize}
\item set of states $Q$ is $\{i, p, q\}$, where $q$ is accepting;
\item input alphabet is $X_\lambda$;
\item stack alphabet is $S$, with initial stack alphabet $\bot$;
\item and whose transition function is described by the following figure:
\begin{center}

\begin{tikzpicture}[->, % makes the edges directed
%stealth’, % makes the arrow heads bold
node distance=5cm, % specifies the minimum distance between two nodes. Change if necessary.
every state/.style={thick, fill=gray!10, inner sep=1pt,minimum size=0pt}, % sets the properties for each ’state’ node
initial text=$ $,]
\node[state, initial] (q1) {$ i$};
\node[state,  right of=q1] (q2) {$ p$};
\node[state, accepting,right of=q2] (q3) {$ q$};
\draw 
(q1) edge[above] node{$
 x, \perp\mapsto \sf{push}(\sigma_n),\dots,\sf{push}(\sigma_1)$} (q2)
(q1) edge[below] node{$
 \text{if } x: \sigma_1\rightarrow\dots\rightarrow\sigma_n$} (q2)
(q2) edge[loop above] node{ $\begin{array}{cccc}
\lambda y, \_ &\mapsto& \sf{push}(\sigma) &   \text{if } y:\sigma\\
\text{@}, \gamma\in S &\mapsto &\sf{pop}&
\end{array}$} (q2)
(q2) edge[above] node{$
\epsilon, \tau \mapsto \sf{pop}
$} (q3);
\end{tikzpicture}
\end{center}
\end{itemize}
A word $w$ is accepted by $A_\tau$ if there is a run that reaches the end of $w$ in the accepting state $q$ with an empty stack. We write $(r, s)\xrightarrow{w} (r', s')$ if there is a run over the word $w$ which starts in the state $r\in Q$ and with a stack $s$ and ends up in the state $r'$ and with a stack $s'$.


By induction on the lenght of the word $w$, we can easily show that:
\begin{lemma}
For every word $w\in X.\{\text{@},\lambda x | x\in X \}^*$, we have that:
 $$(i, \perp)\xrightarrow{w} (p, \sigma_n\dots\sigma_1) \qquad\text{iff} \qquad 
w:\sigma_1\rightarrow\dots\rightarrow\sigma_n$$ 
\end{lemma}

A direct consequence of this lemma is that $A_\tau$ recognizes $W_\tau$. Another direct consequence is that the stack height of $A_\tau$ is bounded (let us say by a number $m$), since the set $S$ used to type the words is finite. Thus $A_\tau$ can be turned into an NFA $N_\tau$, by encoding the stack information in the states. More precisely, the states of $N_\tau$ are pairs $(r,s)$ where $r\in Q$ and $s$ is a stack of height at most $m$, the initial state is $(i,\perp)$ and there is a transition $(r,s)\xrightarrow{a}(r',s')$ where $a\in X_\lambda\cup\{\epsilon\}$ if there is a corresponding run in $A_\tau$. We show in the following that $N_\tau$ is counter-free. 

Let us start with some observations. In the automaton $A_\tau$, the effect of a word $w$ on a stack $s$, starting from the state $p$ is the following: it erases the first $n$ top level elements of $s$, and replaces them by a word $u$. The number $n$ and the word $u$ do not depend on the stack $s$ but only on the word $w$. This is exactly what the following lemma claims.

\begin{lemma}
For every word $w$ over ${X_\lambda}^*$, there is a natural number $n$ and a word $u\in S^*$ such that if $(p,s)\xrightarrow{w}(p,s')$ then $s$ and $s'$ can be decomposed as follows:
$$s=t.v,\qquad s'=t.u\qquad \text{ and }\qquad |v|=n.$$
\end{lemma}
The proof is an easy induction on the lenght of $w$. As a consequence we have that:
\begin{itemize}
\item If $(p,s_1)\xrightarrow{w}(p,s_2)\xrightarrow{w}(p,s_3)$ and $|s_2|>|s_1|$ then $|s_3|>|s_2|$.
\item If $(p,s_1)\xrightarrow{w}(p,s_2)\xrightarrow{w}(p,s_3)$ and $|s_2|<|s_1|$ then $|s_3|<|s_2|$.
\item If $(p,s_1)\xrightarrow{w}(p,s_2)\xrightarrow{w}(p,s_3)$ and $|s_2|=|s_1|$ then $s_3 =s_2$.
\end{itemize}

Let us show that $N_\tau$ is counter-free. Suppose by contradiction that there is a word $w$ and pairwise distinct stacks $s_1,\dots, s_n$ such that 
$(p,s_1)\xrightarrow{w}(p,s_2)\xrightarrow{w}\dots(p,s_n)\xrightarrow{w}(p,s_1)$. By the first two properties above, we have necessarily that $|s_1|=\dots=|s_n|$. Thus by the third property, we have that $s_1=\dots=s_n$, which concludes the proof.
\end{proof}



\subsection{Evaluation of linear $\lambda$-terms}

In this section we show that computing the normal form of $\linterm S X$ terms (that is well-typed linear $\lambda$-terms whose subterms have all types in $S$) is a derivable function:

 \begin{proposition}\label{prop:one-register} 
    For every typed set $X$ and every finite set $S$ of simple types, the function 
    \begin{align*}
        M \in  \linterm S X \qquad \mapsto \qquad \text{normal form of $M$} \in  \linterm S X
    \end{align*}
    is derivable.
\end{proposition}

The proof proceeds by induction on the set of types $S$. The main observation is that, if the evaluation of a redex of type $\sigma\rightarrow \tau$ creates new redexes, then their types are either $\sigma$ or $\tau$ (see Figure~\ref{}), they are in particular in $S\setminus\{\sigma\rightarrow\tau\}$. Thus, we only need to show that the function that evaluates all the redexes of a fixed type is derivable. As we only create stricty smaller redexes, we need to iterate this process only finitely many times, the bound being the size of $S$. 

  Since we have only finitely many typed variables, it is enough to show that the function that evaluates all the redexes of a fixed type $\sigma$ and a fixed variable $x$ is derivable. This will be our goal in the rest of this section.

\begin{theorem}\label{thm:evalOneType}
 For every typed set $X$, every finite set $S$ of simple types and every $x\in X$ and $\sigma\in S$, the function 
    \begin{align*}
        M \in  \linterm S X \quad \mapsto \quad N \in \linterm S X \text{ obtained by reducing all the $x$-redexes of type $\sigma$ in $M$} 
    \end{align*}
    is derivable.
\end{theorem}



\subsubsection{Evaluation of thin $\lambda$-terms}

We start by showing that the evaluation of a restricted class of linear $\lambda$-terms, which we call thin, is an fo tree-to-tree function.   

\begin{definition}[Thin $\lambda$-terms]
We say that the node of a $\lambda$-term is \emph{branching} if its has at least two children which are not ports.
 
A \emph{thin $\lambda$-term} is a term from $\linterm S X$ in which, if a node is branching, then it is an application node of a redex. We denote by $\thinterm S X$ the set of thin $\lambda$-terms.
\end{definition}

Since thin $\lambda$-terms branch only on redexes, the result of their evaluation is word-like (that is, a term where every node has at most one son).  We will show that this word can actually be obtained by a pre-order traversal of the original $\lambda$-term. 
Since pre-order traversal is a basic fo tree-to-tree function, we can conclude that evaluation of thin $\lambda$-terms is a tree-to-tree function as well. 

\begin{center}
Picture 5
\end{center}

\begin{proposition}\label{prop:EvaluateThin}
 For every typed set $X$ and every finite set $S$ of simple types, the function 
    \begin{align*}
        M \in  \thinterm S X \qquad \mapsto \qquad \text{normal form of $M$} \in  \thinterm S X
    \end{align*}
    is derivable.
\end{proposition}

\begin{proof}
Let us show that the evaluation of thin $\lambda$-terms is derivable. We will consider an additional hypothesis on thin $\lambda$-terms:
\begin{center}
\textit{If a node is an application node of a redex, then it is branching.}$\qquad\qquad (H)$
\end{center}
Hypothesis $H$ is the converse of the condition on thin $\lambda$-terms. We will first show that normalisation of thin $\lambda$-terms with this additional condition (let us call them strongly thin $\lambda$-terms) is derivable, then we will show later how to get rid of it.

Let $t$ be a strongly thin $\lambda$-term and let $u$ be its normal form. As noticed before, $u$ has the shape of a word. Moreover, since $t$ is linear, the nodes of $u$ are exactly the nodes of $t$ which are not redexes, nor the variable nodes bound by these redexes. We show that:
\noindent \begin{enumerate}
\item The order in which the inner nodes (ie. non ports) of $u$ appear is the tree order of $t$.
\item Let $n$ be a node of $u$ and $m$ be its corresponding node in $t$. The port $p$ of $u$ is the $i^{th}$ child of $n$ if and only if it the port $p$ of $t$ is the $i^{th}$ port of $m$.  
\end{enumerate} 

To establish the second claim, it is enough to show it for one step of $\beta$-reduction. But this last point is clear by a simple analysis of $\beta$-reduction, as far as we consider that the right child of the $\text{@}$ node of every redex is not a port. This is is guaranteed by the condition $(H)$ of strongly thin $\lambda$-terms. 

To establish the first claim, let us consider two inner nodes $n, m$ of $t$ which are also nodes of $u$, and such that $n$ is smaller than $m$ is the tree order of $t$. We show that $n$ is a descendent of $m$ in $u$. There is two cases to consider:

\textbf{Case 1.} Either $n$ is a descendent of $m$ in $t$, in this case we can conclude easily since $\beta$-reduction preserves the descendent relation. Indeed, by a small analysis of $\beta$-reduction, one can notice that a reduction step may extend the descendent relation, but can never change (or break) the order of two comparable nodes in the original $\lambda$-term.    

\textbf{Case 2.} Otherwise, let us consider the lowest common ancestor $p$ of $m$ and $n$. We proceed by induction on the lenght of the path between $m$ and $p$. By definition of thin $\lambda$-terms, since $p$ is branching it is necessarily an $\text{@}$ node, whose left child $q$ is a binder node, let us say $\lambda x$. 
Notice first that $m$ is smaller (w.r.t. the tree order) than the node $r$ of the variable bound by $q$ . Indeed, if this was not the case, the free variable $r$ would not be bound by the node $q$, as illustrated by the following figure.
\begin{center}
Picture 6
\end{center}
We are then left with the following two situations:
\begin{center}
Picture 7
\end{center}    
And this concludes the proof of the second claim.

Using these ingredients, let us construct an fo tree-to-tree transduction which computes the normal form of thin $\lambda$-terms.
\begin{center}
Picture 8
\end{center}


    \begin{tabular}{ll}
    \pictureline
    {We start by tagging all the redexes of $t$ and their bound variables by $r$. This is an fo rational function, thus it can be performed by a derivable function. The result as a term in $\tmonad (\ranked{\mathcal{A}}+\ranked{\mathcal{A}^r})$, $\ranked{\mathcal{A}^r}$ being a copy of $\ranked{\mathcal{A}}$ where each element is tagged by $r$. Note that the nodes of $u$, the normal form of $t$, are the non-tagged node.}
    { \text{picture a}}
 \pictureline
    {We apply the pre-order traversal function. We get a term in $\tmonad \ranked{\Gamma}$ where $\ranked{\Gamma}:=\ranked{\mathcal{A}}+\ranked{\mathcal{A}^r}+\bullet+\bullet+\bullet$.}
    { \text{picture b}}
 \pictureline
    {Now we need to eliminate the tagged nodes. For that we start by adding the unary symbol $\#$ as a right child of each $\bullet$ node, getting a term in $\tmonad(\ranked{\Gamma+\#})$. This function is clearly derivable. }
    { \text{picture c}}
 \pictureline
    {We apply $\sf{block}^\uparrow$ to separate the symbol $\#$ from the others. We obtain a term in $\ranked{\tmonad(\tmonad \Gamma+\tmonad\#)}$}
    { \text{picture d}}
\pictureline
    {To each kind of blocks,  ($\ranked{\tmonad \Gamma}$ or $\ranked{\tmonad \#}$) we apply the functions $f: \ranked{\tmonad{\Gamma}} \to \ranked{\tmonad(\tmonad \Gamma+\tmonad\#)}$ and $g: \ranked{\tmonad{\#}} \to \ranked{\tmonad(\tmonad \Gamma+\tmonad\#)}$ which are both the identity function, except for the following elements:
    $$
    f(\bullet[\text{@}[\bullet,\bullet],p_1])=f(\bullet[\lambda x^\sigma\bullet],p_1])=f(\bullet[x^\sigma,p_1])=\bullet[p_1]$$
    
    For every n-ary element of $\ranked{\mathcal{A}}$, we have that:
 $$\begin{array}{c}
  f(\bullet[a[p_{i_1},\dots,p_{i_k}, \bullet, p_{i_{k+1}},\dots, p_{i_{n-1}}],p_{i_n}])\\
  =a[p_{i_1},\dots,p_{i_k}, p_{i_n}, p_{i_{k+1}},\dots, p_{i_{n-1}}]\\
f(\bullet[a[p_1,\dots,p_n]])=a[p_1,\dots,p_n]\\
g(\#[p_1])=p_1
\end{array}$$
After that, we apply a flattening, to get a term in $\ranked{\tmonad(\Gamma+\#)}$.
}
{ \text{picture e}}
\pictureline
{We have got the desired term, but not with the desired type. To obtain a term in $\ranked{\tmonad{\mathcal{A}}}$, we transform each tagged element of $\ranked{\mathcal{A}^r}$ into its untagged version, transform $\bullet_2$ into $\text{@}$, and $\bullet_0$ into $x^\sigma$. Finally, we erase the symbols $\#$ and $\bullet_1$.}{}
    \end{tabular}

 
\end{proof}

  



\subsubsection{Factorizing $\lambda$-terms into blocks of thin $\lambda$-terms}

\begin{definition}[Full redex]
Let $t$ be a linear $\lambda$-term, $x$ be a typed variable and $\sigma$ be a simple type. A \emph{full $x$-redex of type $\sigma$} is a set of nodes  containing an $x$-redex of type $\sigma$, the node of the variable $x$ bound by this redex, together with the set of nodes between them.
\end{definition}
Picture 9


\begin{proposition}\label{prop:FactoIntoThin}
For every typed variable $x$, and every simple type $\sigma$, there is a factorisation $f:\tmonad \ranked{X^\lambda} \to \tmonad(\tmonad \ranked{X^\lambda})$ such that for every $t\in\linterm S X$
\begin{itemize}
\item every full $x$-redex of type $\sigma$ in $t$ is entirely contained in one of the factors of $f(t)$;
\item the factors of $f(t)$ are thin $\lambda$-terms.
\end{itemize}
\end{proposition}

\begin{proof}
We define the function $f$ as the composition of the following three functions
\begin{align*}
\tmonad \ranked{X^\lambda} \xrightarrow{\quad g\quad} \tmonad (\ranked{X^\lambda}+\bullet) \xrightarrow{\quad \mathsf{block}^\uparrow\quad} \tmonad (\tmonad\ranked{X^\lambda}+\tmonad\bullet)
\xrightarrow{\quad \mathsf{erase}\quad} \tmonad \tmonad\ranked{X^\lambda}
\end{align*}
The function $g$ is a first-order rational tree function, which indicates, using the unary symbol $\bullet$, the places wheres two distinct blocks of $f$ will be separated. We will describe it more precisely a bit later. The function $\mathsf{block}^\uparrow$ will create these blocks and finally, we erase the all the occurrences of the symbol $\bullet$.
Each of these functions is derivable: $g$ thanks to Proposition~\ref{prop:forat}, $\mathsf{block}^\uparrow$ being a basic function, and $\mathsf{erase}$ has been show derivable in Example~\ref{}. Their composition is then derivable as well.
 
Now we define a first-order rational function $g:$ and show that the $\bullet$-nodes it introduces creates blocks staisfying the conditions 1 and 2 of Proposition~\ref{}, when the input term is in $\linterm S X$.  
We define $g$ as the composition of the characteristic function of three first-order unary queries: $\mathsf{@redex}, \mathsf{Right}$ and $\mathsf{Left}$, followed by an homomorphims $h$. We define them in the following:
\begin{itemize}
\item The property $\mathsf{@Redex}$ checks whether a node is the application node of an $x$-redex of type $\sigma$. It can be expressed by the following first-order formula, where  $\varphi_\sigma$ is a first-order formula which decides if the type of a node is $\sigma$ (for insatnce the one given by Lemma~\ref{lem:IsTypeTauFo}):
\begin{align*} \mathsf{@Redex}( u ):=& \mathsf{@}(u)\ \wedge\ \lambda x(\mathrm{Child}_1(u))\ \wedge\ \varphi_\sigma(\mathrm{Child}_1(u))
\end{align*} 
\item The query $\mathsf{Right}$ (resp. $\mathsf{Left}$) checks if the node is an application node, which lies, together with his right (resp. left) child, strictly between an $x$-redex of type $\sigma$ and the node it binds. Those properties can be expressed by the following first-order formula:
\begin{align*}
\mathsf{Right}( u ):=&\ @(u)\ \wedge\ \exists v\exists w . \ (w< \mathrm{Child}_2(u))\ \wedge\ (u< v)\ \wedge \ \mathsf{@ redex}(v) \ \wedge\ (\mathrm{Child}_1(v)\ \mathsf{binds}\ w)\\
\mathsf{Left}( u ):=&\ @(u)\ \wedge\  \exists v\exists w . \ (w< \mathrm{Child}_1(u))\ \wedge\ (u< v)\ \wedge \ \mathsf{@ redex}(v) \ \wedge\ (\mathrm{Child}_1(v)\ \mathsf{binds}\ w)
\end{align*} 
Where $u\ \mathsf{binds} \ v$ is a binary query indicating that $u$ is an abstarction node which binds the node $v$. This is a first-order relation, and can be described by the following formula for example:
\begin{align*}
 u\ \mathsf{binds}\ v :=&\bigvee_{y\in X} \lambda y(u) \wedge y(v) \wedge (\forall w. \ \ v< w< u\Rightarrow \neg \lambda y(w))
 \end{align*}
\end{itemize}

When we apply the characteristic functions of these queries to a term in $\tmonad X^\lambda$, each node will be decorated by three informations: whether is satisfies or not $\mathsf{@Redex}$,  whether is satisfies or not $\mathsf{Right}$ and whether is satisfies or not $\mathsf{Left}$. Note that for linear $\lambda$-terms, some combinations of these properties cannot hold in the same node. For instance, a node cannot satisfy $\mathsf{Right}$ and $\mathsf{Left}$ simultanously, as this would contradict linearity. 

Now we define the homomorphism $h$, which maps the $\lambda$-terms with these three informations to terms of $\tmonad (\ranked{X^\lambda}+\bullet)$. We define $h$ by his action to each node, depending on its label and the three informations it contains:
$$\begin{array}{|l|l|l|l|l|l|}
\hline
\neg\mathsf{@Redex} \wedge \mathsf{Right} & \neg\mathsf{@Redex} \wedge \mathsf{Left} & \neg\mathsf{@Redex} \wedge \neg\mathsf{Right} \wedge \neg\mathsf{Left} & \mathsf{@Redex} &  \lambda y & y\\
\hline
\end{array}$$

Let $t$ be a term in $\linterm S X$. We show that the factors of $g(t)$ satisfy the two conditions of Proposition~\ref{prop:FactoIntoThin}. First of all, by analyzing the action of $h$ on each node, note that every $@$ node of $g(t)$ has $\bullet$ as one of its children, except when it is satisfies $\mathsf{@Redex}$. Thus the only branching nodes in a factor are redexes, hence the factors are thin. Now suppose by contradiction that there is some full $x$-redex of type $\sigma$ of $t$ which is not entirely contained in a factor of $g(t)$. This means that in $g(t)$ there is a $\bullet$ between the application node of the redex (call it $u$) and the variable it binds (call it $v$). Equivalently, there is a node $n$ in $t$ between $u$ and $v$ which satisfies one of the first three conditions of table~\ref{}.  Suppose that the right child of $n$ is also in the path between $u$ and $v$, the symetric case can be treated similarly. In particular, $n$ satisfies $\mathsf{Right}$. But in this case $\bullet$ would be the left child of $n$ in $g(t)$ and this gives 
\end{proof}
\subsubsection{$\beta$-reduction commutes with factorization} The last ingredient to show Thm.~\ref{thm:evalOneType} is to notice  that factorizing a term, applying some $\beta$-reduction steps to the factors, then flattening, can be simulated by appliying  $\beta$-reduction steps directly to the original $\lambda$-term.

Let us state this property more formally. For that, we can generalise the lifting of functions to the lifting of relations as follows. 
Let $\Sigma$ be a ranked set. If $R\subseteq \ranked{\Sigma}\times\ranked{\Sigma}$ is an arity preseving relation (that is $\arity{u}=\arity{v}$ whenever $(u,v)\in R$), then $R$ can be lifted to $\tmonad R\subseteq \ranked{\tmonad \Sigma} \times \ranked{\tmonad \Sigma}$ in a natural way. 

Since $\beta$-reduction is an arity preserving relation  over linear $\lambda$-terms, its reflexive transitive closure $\beta^*$ is arity preserving as well.  We can lift then the later to $\tmonad \beta^*\subseteq \linterm S X\times\linterm S X$.
The following proposition is a direct consequence from the fact that $\beta$ is a congruence on terms.

\begin{proposition}\label{prop:betaCommutesWithFacto}
For every foctorization $f:\linterm S X \to \linterm S X$ and every linear $\lambda$-term $M$
$$\text{if }\qquad f(M) \xrightarrow{\tmonad \beta^*} N \qquad\text{ then }\qquad M\xrightarrow{\beta^*} \flatt(N).$$
\end{proposition}


\subsubsection{Gathering all the pieces.}
Theorem~\ref{thm:evalOneType} follows easily from Propositions~\ref{prop:EvaluateThin},\ref{prop:betaCommutesWithFacto} and \ref{prop:FactoIntoThin}.

\begin{proof}[Proof of Theorem.~\ref{thm:evalOneType}]
Let us show that the evaluation of all  $x^\sigma$-redexes of type $\sigma\rightarrow\tau$ is derivable. We start by applying to our $\lambda$-term the factorisation $f$ from Prop.~\ref{prop:FactoIntoThin}. As the factors are thin $\lambda$-terms, we can evaluate them by lifting the function from Prop.~\ref{prop:EvaluateThin}. We apply a flat to obtain again a $\lambda$-term. The later is a $\beta^*$-redex of the original $\lambda$-term by Prop.~\ref{prop:betaCommutesWithFacto}. Moreover, since every full-redex of the original $\lambda$-term was in one of the factors, all the $x^\sigma$-redexes has been reduced, which concludes the proof. 
\end{proof}